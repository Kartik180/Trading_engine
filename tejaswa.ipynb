{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from arch import arch_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    df = pd.read_csv('sample_input.csv')\n",
    "     \n",
    "    actual_close = np.loadtxt('sample_close.txt')\n",
    "    \n",
    "    pred_close = predict_func(df)\n",
    "    \n",
    "    # Calculation of squared_error\n",
    "    actual_close = np.array(actual_close)\n",
    "    pred_close = np.array(pred_close)\n",
    "    mean_square_error = np.mean(np.square(actual_close-pred_close))\n",
    "\n",
    "\n",
    "    pred_prev = [df['Close'].iloc[-1]]\n",
    "    pred_prev.append(pred_close[0])\n",
    "    pred_curr = pred_close\n",
    "    \n",
    "    actual_prev = [df['Close'].iloc[-1]]\n",
    "    actual_prev.append(actual_close[0])\n",
    "    actual_curr = actual_close\n",
    "\n",
    "    # Calculation of directional_accuracy\n",
    "    pred_dir = np.array(pred_curr)[:, 0] - np.array(pred_prev[1])\n",
    "    actual_dir = np.array(actual_curr) - np.array(actual_prev)\n",
    "    dir_accuracy = np.mean((pred_dir*actual_dir)>0)*100\n",
    "\n",
    "    print(f'Mean Square Error: {mean_square_error:.6f}\\nDirectional Accuracy: {dir_accuracy:.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_func(df):\n",
    "    df.ffill(inplace=True)\n",
    "    # Prepare the DataFrame with log returns\n",
    "    df['log_returns'] = np.log(df['Close']).diff().dropna()\n",
    "    # Create a scaler to normalize the data\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_data = scaler.fit_transform(df['Close'].values.reshape(-1, 1))\n",
    "    # Split the data into training and test sets\n",
    "    train_size = int(len(scaled_data) * 0.8)\n",
    "    train_data = scaled_data[:train_size]\n",
    "    test_data = scaled_data[train_size:]\n",
    "\n",
    "    # Prepare the training data for LSTM\n",
    "    X_train_lstm, y_train_lstm = [], []\n",
    "    lookback_lstm = 10  # Adjust the lookback window for LSTM\n",
    "\n",
    "    for i in range(lookback_lstm, len(train_data)):\n",
    "        X_train_lstm.append(train_data[i-lookback_lstm:i, 0])\n",
    "        y_train_lstm.append(train_data[i, 0])\n",
    "\n",
    "    X_train_lstm, y_train_lstm = np.array(X_train_lstm), np.array(y_train_lstm)\n",
    "\n",
    "    # Reshape the input data for LSTM\n",
    "    X_train_lstm = np.reshape(X_train_lstm, (X_train_lstm.shape[0], X_train_lstm.shape[1], 1))\n",
    "\n",
    "    # Create and fit the LSTM model\n",
    "    lstm_model = Sequential()\n",
    "    lstm_model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train_lstm.shape[1], 1)))\n",
    "    lstm_model.add(LSTM(units=50))\n",
    "    lstm_model.add(Dense(units=1))\n",
    "    lstm_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    lstm_model.fit(X_train_lstm, y_train_lstm, epochs=10, batch_size=32)\n",
    "\n",
    "    # Prepare the test data for LSTM\n",
    "    inputs_lstm = df['Close'].values[len(df) - len(test_data) - lookback_lstm:]\n",
    "    inputs_lstm = inputs_lstm.reshape(-1, 1)\n",
    "    inputs_lstm = scaler.transform(inputs_lstm)\n",
    "\n",
    "    X_test_lstm = []\n",
    "\n",
    "    for i in range(lookback_lstm, len(inputs_lstm)):\n",
    "        X_test_lstm.append(inputs_lstm[i-lookback_lstm:i, 0])\n",
    "\n",
    "    X_test_lstm = np.array(X_test_lstm)\n",
    "    X_test_lstm = np.reshape(X_test_lstm, (X_test_lstm.shape[0], X_test_lstm.shape[1], 1))\n",
    "\n",
    "    # Make predictions using LSTM model\n",
    "    predicted_prices_lstm = lstm_model.predict(X_test_lstm)\n",
    "    predicted_prices_lstm = scaler.inverse_transform(predicted_prices_lstm)\n",
    "\n",
    "    # Prepare the test data for EMA\n",
    "    inputs_ema = df['Close'].values[len(df) - len(test_data) - lookback_lstm:]\n",
    "    inputs_ema = inputs_ema.reshape(-1, 1)\n",
    "    inputs_ema = scaler.transform(inputs_ema)\n",
    "\n",
    "    # Calculate EMA using alpha 0.75\n",
    "    ema = [inputs_ema[0]]  # Initialize the first EMA value as the first data point\n",
    "    alpha = 0.85\n",
    "    for i in range(1, len(inputs_ema)):\n",
    "        ema_value = alpha * inputs_ema[i] + (1 - alpha) * ema[i - 1]\n",
    "        ema.append(ema_value)\n",
    "\n",
    "    ema = np.array(ema)\n",
    "    ema = scaler.inverse_transform(ema)\n",
    "\n",
    "    # Adjust the shapes of predicted_prices_lstm and ema arrays\n",
    "    predicted_prices_lstm = predicted_prices_lstm[-len(ema):]\n",
    "\n",
    "    # Combine the predictions\n",
    "    combined_predictions = 0.05 * predicted_prices_lstm[-10:] + 0.95 * ema[-10:]\n",
    "    # Return the combined predictions for the next two days\n",
    "    next_two_days = combined_predictions[-2:]\n",
    "    return next_two_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('STOCK_INDEX.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "68/68 [==============================] - 3s 6ms/step - loss: 0.0092\n",
      "Epoch 2/10\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 2.2183e-04\n",
      "Epoch 3/10\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 2.1664e-04\n",
      "Epoch 4/10\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 2.0160e-04\n",
      "Epoch 5/10\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 2.0262e-04\n",
      "Epoch 6/10\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 2.0610e-04\n",
      "Epoch 7/10\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 2.6514e-04\n",
      "Epoch 8/10\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 1.9641e-04\n",
      "Epoch 9/10\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 2.0878e-04\n",
      "Epoch 10/10\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 2.0944e-04\n",
      "17/17 [==============================] - 1s 2ms/step\n",
      "[[14608.71902817]\n",
      " [14405.39633091]\n",
      " [14322.24372831]\n",
      " [14397.12505422]\n",
      " [14354.61268808]\n",
      " [14462.34132643]\n",
      " [14612.68030848]\n",
      " [14805.38090981]\n",
      " [14860.66604771]\n",
      " [14657.38908735]]\n"
     ]
    }
   ],
   "source": [
    "df.ffill(inplace=True)\n",
    "\n",
    "# Prepare the DataFrame with log returns\n",
    "df['log_returns'] = np.log(df['Close']).diff().dropna()\n",
    "\n",
    "# Create a scaler to normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(df['Close'].values.reshape(-1, 1))\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train_size = int(len(scaled_data) * 0.8)\n",
    "train_data = scaled_data[:train_size]\n",
    "test_data = scaled_data[train_size:]\n",
    "\n",
    "# Prepare the training data for LSTM\n",
    "X_train_lstm, y_train_lstm = [], []\n",
    "lookback_lstm = 10  # Adjust the lookback window for LSTM\n",
    "\n",
    "for i in range(lookback_lstm, len(train_data)):\n",
    "    X_train_lstm.append(train_data[i-lookback_lstm:i, 0])\n",
    "    y_train_lstm.append(train_data[i, 0])\n",
    "\n",
    "X_train_lstm, y_train_lstm = np.array(X_train_lstm), np.array(y_train_lstm)\n",
    "\n",
    "# Reshape the input data for LSTM\n",
    "X_train_lstm = np.reshape(X_train_lstm, (X_train_lstm.shape[0], X_train_lstm.shape[1], 1))\n",
    "\n",
    "# Create and fit the LSTM model\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train_lstm.shape[1], 1)))\n",
    "lstm_model.add(LSTM(units=50))\n",
    "lstm_model.add(Dense(units=1))\n",
    "lstm_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "lstm_model.fit(X_train_lstm, y_train_lstm, epochs=10, batch_size=32)\n",
    "\n",
    "# Prepare the test data for LSTM\n",
    "inputs_lstm = df['Close'].values[len(df) - len(test_data) - lookback_lstm:]\n",
    "inputs_lstm = inputs_lstm.reshape(-1, 1)\n",
    "inputs_lstm = scaler.transform(inputs_lstm)\n",
    "\n",
    "X_test_lstm = []\n",
    "\n",
    "for i in range(lookback_lstm, len(inputs_lstm)):\n",
    "    X_test_lstm.append(inputs_lstm[i-lookback_lstm:i, 0])\n",
    "\n",
    "X_test_lstm = np.array(X_test_lstm)\n",
    "X_test_lstm = np.reshape(X_test_lstm, (X_test_lstm.shape[0], X_test_lstm.shape[1], 1))\n",
    "\n",
    "# Make predictions using LSTM model\n",
    "predicted_prices_lstm = lstm_model.predict(X_test_lstm)\n",
    "predicted_prices_lstm = scaler.inverse_transform(predicted_prices_lstm)\n",
    "\n",
    "# Prepare the test data for EMA\n",
    "inputs_ema = df['Close'].values[len(df) - len(test_data) - lookback_lstm:]\n",
    "inputs_ema = inputs_ema.reshape(-1, 1)\n",
    "inputs_ema = scaler.transform(inputs_ema)\n",
    "\n",
    "# Calculate EMA using alpha 0.85\n",
    "ema = [inputs_ema[0]]  # Initialize the first EMA value as the first data point\n",
    "alpha = 0.85\n",
    "for i in range(1, len(inputs_ema)):\n",
    "    ema_value = alpha * inputs_ema[i] + (1 - alpha) * ema[i - 1]\n",
    "    ema.append(ema_value)\n",
    "\n",
    "ema = np.array(ema)\n",
    "ema = scaler.inverse_transform(ema)\n",
    "\n",
    "# Adjust the shapes of predicted_prices_lstm and ema arrays\n",
    "predicted_prices_lstm = predicted_prices_lstm[-len(ema):]\n",
    "\n",
    "# Combine the predictions\n",
    "combined_predictions = 0.05 * predicted_prices_lstm[-10:] + 0.95 * ema[-10:]\n",
    "print(combined_predictions)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
