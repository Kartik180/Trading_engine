{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the function to create and train the LSTM model\n",
    "def create_model_and_train(df):\n",
    "    df.ffill(inplace=True)\n",
    "    # Prepare the DataFrame with log returns\n",
    "    df['log_returns'] = np.log(df['Close']).diff().dropna()\n",
    "\n",
    "    # Create a scaler to normalize the data\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_data = scaler.fit_transform(df['Close'].values.reshape(-1, 1))\n",
    "\n",
    "    # Split the data into training and test sets\n",
    "    train_size = int(len(scaled_data) * 0.8)\n",
    "    train_data = scaled_data[:train_size]\n",
    "    test_data = scaled_data[train_size:]\n",
    "\n",
    "    # Prepare the training data for LSTM\n",
    "    X_train_lstm, y_train_lstm = [], []\n",
    "    lookback_lstm = 10  # Adjust the lookback window for LSTM\n",
    "\n",
    "    for i in range(lookback_lstm, len(train_data)):\n",
    "        X_train_lstm.append(train_data[i-lookback_lstm:i, 0])\n",
    "        y_train_lstm.append(train_data[i, 0])\n",
    "\n",
    "    X_train_lstm, y_train_lstm = np.array(X_train_lstm), np.array(y_train_lstm)\n",
    "\n",
    "    # Reshape the input data for LSTM\n",
    "    X_train_lstm = np.reshape(X_train_lstm, (X_train_lstm.shape[0], X_train_lstm.shape[1], 1))\n",
    "\n",
    "    # Create and fit the LSTM model\n",
    "    lstm_model = Sequential()\n",
    "    lstm_model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train_lstm.shape[1], 1)))\n",
    "    lstm_model.add(LSTM(units=50))\n",
    "    lstm_model.add(Dense(units=1))\n",
    "    lstm_model.compile(optimizer='adam', loss='mean_squared_error' , run_eagerly=True)\n",
    "    lstm_model.fit(X_train_lstm, y_train_lstm, epochs=10, batch_size=32)\n",
    "\n",
    "    return lstm_model, scaler, lookback_lstm\n",
    "\n",
    "# Define the function to make predictions using the trained model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(df, lstm_model, scaler, lookback_lstm):\n",
    "    # Prepare the test data for LSTM\n",
    "    inputs_lstm = df['Close'].values[len(df) - lookback_lstm:]\n",
    "    inputs_lstm = inputs_lstm.reshape(-1, 1)\n",
    "    inputs_lstm = scaler.transform(inputs_lstm)\n",
    "\n",
    "    X_test_lstm = []\n",
    "\n",
    "    for i in range(lookback_lstm, len(inputs_lstm)):\n",
    "        X_test_lstm.append(inputs_lstm[i-lookback_lstm:i, 0])\n",
    "\n",
    "    X_test_lstm = np.array(X_test_lstm)\n",
    "\n",
    "    # Reshape the input data for LSTM\n",
    "    X_test_lstm = np.reshape(X_test_lstm, (X_test_lstm.shape[0], lookback_lstm, 1))\n",
    "\n",
    "    # Make predictions using the LSTM model\n",
    "    predicted_prices_lstm = lstm_model.predict(X_test_lstm)\n",
    "    predicted_prices_lstm = scaler.inverse_transform(predicted_prices_lstm)\n",
    "\n",
    "    # Return the predicted prices\n",
    "    return predicted_prices_lstm\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# Assuming you have a new dataset stored in a DataFrame named 'new_data'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "68/68 [==============================] - 9s 132ms/step - loss: 0.0060\n",
      "Epoch 2/10\n",
      "68/68 [==============================] - 10s 144ms/step - loss: 2.0391e-04\n",
      "Epoch 3/10\n",
      "68/68 [==============================] - 8s 124ms/step - loss: 1.9938e-04\n",
      "Epoch 4/10\n",
      "68/68 [==============================] - 9s 137ms/step - loss: 2.0581e-04\n",
      "Epoch 5/10\n",
      "68/68 [==============================] - 9s 136ms/step - loss: 2.1158e-04\n",
      "Epoch 6/10\n",
      "68/68 [==============================] - 9s 137ms/step - loss: 1.9004e-04\n",
      "Epoch 7/10\n",
      "68/68 [==============================] - 9s 135ms/step - loss: 1.8628e-04\n",
      "Epoch 8/10\n",
      "68/68 [==============================] - 9s 131ms/step - loss: 1.9026e-04\n",
      "Epoch 9/10\n",
      "68/68 [==============================] - 10s 152ms/step - loss: 1.8913e-04\n",
      "Epoch 10/10\n",
      "68/68 [==============================] - 9s 136ms/step - loss: 1.8705e-04\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unexpected result of `predict_function` (Empty batch_outputs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m new_data2\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39msample_input.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[39m# Make predictions using the trained model\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m predictions \u001b[39m=\u001b[39m make_predictions(new_data2, model, scaler, lookback)\n\u001b[0;32m     10\u001b[0m \u001b[39m# Print the predicted prices\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[39mprint\u001b[39m(predictions)\n",
      "Cell \u001b[1;32mIn[48], line 18\u001b[0m, in \u001b[0;36mmake_predictions\u001b[1;34m(df, lstm_model, scaler, lookback_lstm)\u001b[0m\n\u001b[0;32m     15\u001b[0m X_test_lstm \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mreshape(X_test_lstm, (X_test_lstm\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], lookback_lstm, \u001b[39m1\u001b[39m))\n\u001b[0;32m     17\u001b[0m \u001b[39m# Make predictions using the LSTM model\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m predicted_prices_lstm \u001b[39m=\u001b[39m lstm_model\u001b[39m.\u001b[39;49mpredict(X_test_lstm)\n\u001b[0;32m     19\u001b[0m predicted_prices_lstm \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39minverse_transform(predicted_prices_lstm)\n\u001b[0;32m     21\u001b[0m \u001b[39m# Return the predicted prices\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\karti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\karti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:2579\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2575\u001b[0m                 callbacks\u001b[39m.\u001b[39mon_predict_batch_end(\n\u001b[0;32m   2576\u001b[0m                     end_step, {\u001b[39m\"\u001b[39m\u001b[39moutputs\u001b[39m\u001b[39m\"\u001b[39m: batch_outputs}\n\u001b[0;32m   2577\u001b[0m                 )\n\u001b[0;32m   2578\u001b[0m     \u001b[39mif\u001b[39;00m batch_outputs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 2579\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   2580\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUnexpected result of `predict_function` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2581\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m(Empty batch_outputs). Please use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2582\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`Model.compile(..., run_eagerly=True)`, or \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2583\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`tf.config.run_functions_eagerly(True)` for more \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2584\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39minformation of where went wrong, or file a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2585\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39missue/bug to `tf.keras`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2586\u001b[0m         )\n\u001b[0;32m   2587\u001b[0m     callbacks\u001b[39m.\u001b[39mon_predict_end()\n\u001b[0;32m   2588\u001b[0m all_outputs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mmap_structure_up_to(\n\u001b[0;32m   2589\u001b[0m     batch_outputs, potentially_ragged_concat, outputs\n\u001b[0;32m   2590\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: Unexpected result of `predict_function` (Empty batch_outputs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`."
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('STOCK_INDEX.csv')\n",
    "\n",
    "# Create and train the LSTM model\n",
    "model, scaler, lookback = create_model_and_train(train_data)\n",
    "\n",
    "new_data2=pd.read_csv('sample_input.csv')\n",
    "# Make predictions using the trained model\n",
    "predictions = make_predictions(new_data2, model, scaler, lookback)\n",
    "\n",
    "# Print the predicted prices\n",
    "print(predictions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
